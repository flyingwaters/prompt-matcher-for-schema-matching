{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T11:23:48.621699Z",
     "iopub.status.busy": "2023-11-07T11:23:48.621399Z",
     "iopub.status.idle": "2023-11-07T11:23:50.932065Z",
     "shell.execute_reply": "2023-11-07T11:23:50.931443Z",
     "shell.execute_reply.started": "2023-11-07T11:23:48.621681Z"
    }
   },
   "outputs": [],
   "source": [
    "# CRS 读入\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = r\"./CRS/Musicians_joinable\"\n",
    "\n",
    "def process_crs(path:str):\n",
    "    correspondence_set = []\n",
    "    with open(path, \"r\") as f:\n",
    "        matchings = json.load(f)\n",
    "    for m in matchings:\n",
    "        for c in m:\n",
    "            if c not in correspondence_set:\n",
    "                correspondence_set.append(c)\n",
    "    Views = []\n",
    "    for match in matchings:\n",
    "        view = []\n",
    "        for c in correspondence_set:\n",
    "            if c in match:\n",
    "                view.append(1)\n",
    "            else:\n",
    "                view.append(0)\n",
    "        Views.append(view)\n",
    "    prob = np.array([float(1/len(matchings)) for i in range(len(matchings))])\n",
    "    \n",
    "    correspondence_count = {tuple(i):0 for i in correspondence_set}\n",
    "    \n",
    "    return np.array(Views, dtype=int), matchings, prob, correspondence_set, correspondence_count\n",
    "\n",
    "def read_correspondence_pd(source_path, target_path):\n",
    "    source_df = pd.read_csv(source_path)\n",
    "    target_df = pd.read_csv(target_path)\n",
    "    return source_df, target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 chatgpt 的 tokenzier，用于估计correspondence 的cost func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T11:23:50.933247Z",
     "iopub.status.busy": "2023-11-07T11:23:50.932893Z",
     "iopub.status.idle": "2023-11-07T11:23:51.167738Z",
     "shell.execute_reply": "2023-11-07T11:23:51.167213Z",
     "shell.execute_reply.started": "2023-11-07T11:23:50.933221Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T11:23:51.169398Z",
     "iopub.status.busy": "2023-11-07T11:23:51.169085Z",
     "iopub.status.idle": "2023-11-07T11:23:51.749503Z",
     "shell.execute_reply": "2023-11-07T11:23:51.749027Z",
     "shell.execute_reply.started": "2023-11-07T11:23:51.169376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "39\n",
      "25\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "for path in [ r\"./CRS/Musicians_joinable\",  r\"./CRS/Musicians_unionable\",  r\"./CRS/Musicians_semjoinable\",  r\"./CRS/Musicians_viewunion\"]:\n",
    "    View, matchings, prob, c_set, correspondence_count = process_crs(path)\n",
    "    print(len(c_set))\n",
    "source_pth = r\"/root/autodl-tmp/prompt-matcher-reduce-uncertainty/Valentine-datasets/Wikidata/Musicians/Musicians_joinable/musicians_joinable_source.csv\"\n",
    "target_pth = r\"/root/autodl-tmp/prompt-matcher-reduce-uncertainty/Valentine-datasets/Wikidata/Musicians/Musicians_joinable/musicians_joinable_target.csv\"\n",
    "source_df, target_df = read_correspondence_pd(source_path=source_pth, target_path=target_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理后生成 facts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T11:23:51.750371Z",
     "iopub.status.busy": "2023-11-07T11:23:51.750153Z",
     "iopub.status.idle": "2023-11-07T11:23:52.229759Z",
     "shell.execute_reply": "2023-11-07T11:23:52.229268Z",
     "shell.execute_reply.started": "2023-11-07T11:23:51.750357Z"
    }
   },
   "outputs": [],
   "source": [
    "from fact import FactSet\n",
    "len_list = np.array([0]*123)\n",
    "ex_fact = FactSet(facts=View, prior_p=prob, ground_true=2, len_list=len_list)\n",
    "random_fact = FactSet(facts=View, prior_p=prob, ground_true=2, len_list=len_list)\n",
    "brute_fact = FactSet(facts=View, prior_p=prob, ground_true=2, len_list=len_list)\n",
    "heuristic_fact = FactSet(facts=View, prior_p=prob, ground_true=2, len_list=len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selector to select correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T11:23:52.230614Z",
     "iopub.status.busy": "2023-11-07T11:23:52.230375Z",
     "iopub.status.idle": "2023-11-07T11:23:52.738759Z",
     "shell.execute_reply": "2023-11-07T11:23:52.738266Z",
     "shell.execute_reply.started": "2023-11-07T11:23:52.230599Z"
    }
   },
   "outputs": [],
   "source": [
    "from query import QuerySelector, BaseQuerySelector, GreedyQuerySelector,RandomQuerySelector, HeuristicQuerySelector\n",
    " # 对应fact1, 3是0.8, 0.\n",
    "query_selector = GreedyQuerySelector()\n",
    "# selection_idxes, sub_facts, h = query_selector.select(ex_fact, 2, accuracy, cost_func=2)\n",
    "random_selector = RandomQuerySelector()\n",
    "base_selector = BaseQuerySelector()\n",
    "h_selector = HeuristicQuerySelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T11:23:53.788909Z",
     "iopub.status.busy": "2023-11-07T11:23:53.788694Z",
     "iopub.status.idle": "2023-11-07T11:23:54.037137Z",
     "shell.execute_reply": "2023-11-07T11:23:54.036682Z",
     "shell.execute_reply.started": "2023-11-07T11:23:53.788895Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_base = \"https://openkey.cloud/v1\"\n",
    "openai.api_key = \"tokens\"\n",
    "def query_chatgpt(message_param):\n",
    "    sentence = openai.ChatCompletion.create(\n",
    "                                    model=\"gpt-4-0613\",\n",
    "                                    messages= [{\"role\": \"user\", \"content\": message_param}],\n",
    "                                    # 流式输出\n",
    "                                    temperature=0.8,\n",
    "                                    stream = False)\n",
    "    \n",
    "    return sentence[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_make(attribute_name1, attribute_name2, values1, values2):\n",
    "    k = \"\"\"Determine the two attributes can be took as the same attribute in schema match. Remember some tips.\n",
    "Tips:\n",
    "(1) These two schemas are used to store Real-world information\n",
    "(2) Some letters are extracted from the full names and merged into an abbreviation word.\n",
    "(3) Schema information sometimes is also added as the prefix of abbreviation.\n",
    "(4) values exchange verification: match would be likely correct, if the second value instances are also suitable for the first attribute name.\n",
    "Input:\n",
    "First Attribute Name: {attribute_name} \n",
    "its Value instances: {values} \n",
    "\n",
    "Second Attribute Name: {attribute_name2} \n",
    "Its Value instances: {values2}. \\n\n",
    "Please answer with [yes or no]\"\"\".format(attribute_name=attribute_name1, attribute_name2=attribute_name2, values=values1, values2=values2)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T11:23:54.037964Z",
     "iopub.status.busy": "2023-11-07T11:23:54.037759Z",
     "iopub.status.idle": "2023-11-07T11:23:54.315624Z",
     "shell.execute_reply": "2023-11-07T11:23:54.315133Z",
     "shell.execute_reply.started": "2023-11-07T11:23:54.037950Z"
    }
   },
   "outputs": [],
   "source": [
    "def post_p_caculate(prior_p, p_a_v, p_a):\n",
    "    return prior_p*p_a_v / p_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  our近似算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from query import get_values\n",
    "cost_sum = 0\n",
    "turns = 3\n",
    "\n",
    "\n",
    "c_len = ex_fact.num_fact()\n",
    "acc = np.array([[0.92 for i in range(c_len)]])\n",
    "approx_h_list = []\n",
    "c_index_list = [i for i in range(ex_fact.num_fact())]\n",
    "\n",
    "\n",
    "while turns>0:\n",
    "    print(\"start round\")\n",
    "    start = time.time()\n",
    "    selection_idxes, h = query_selector.select(ex_fact, 80, acc , cost_func=2, \n",
    "                                                          target_pd=target_df, source_pd=source_df,\n",
    "                                                          correspondence_count=correpondence_count, correspondence_set=c_set, c_index_list=c_index_list)\n",
    "    end = time.time()\n",
    "    print(selection_idxes)\n",
    "    gap_time = end - start\n",
    "    print(f\"1 round cost {gap_time}\")\n",
    "    c_index_list = [k for k in c_index_list if k not in selection_idxes]\n",
    "    ans = []\n",
    "    for c_id in selection_idxes:\n",
    "        c_name = c_set[c_id]\n",
    "        print(c_name)\n",
    "        correpondence_count[tuple(c_name)]+=1\n",
    "        information = 'assay'\n",
    "        v1, v2 = get_values(source_pd=source_df, target_pd=target_df, correspondence_count=correpondence_count, c_name=c_name)\n",
    "        prompt = prompt_make(c_name[0], c_name[1], v1, v2)\n",
    "        print(\"prompt:\",prompt)\n",
    "        answer = query_chatgpt(prompt).lower()\n",
    "        print(answer)\n",
    "        if 'yes' in answer:     \n",
    "            ans.append(1)\n",
    "        else:\n",
    "            ans.append(0)\n",
    "    turns -=1\n",
    "    p_a,p_a_v = ex_fact.compute_ans_p(ans, selection_idxes, acc)\n",
    "    p_post = ex_fact.get_prior_p()*p_a_v/p_a\n",
    "    ex_fact.set_prior_p(p_post)\n",
    "    approx_h_list.append(ex_fact.compute_entropy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item_bool in enumerate(list(ex_fact.facts[-1])):\n",
    "    if item_bool:\n",
    "        print(idx)\n",
    "        print(c_set[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-11-07T11:23:56.995629Z",
     "iopub.status.busy": "2023-11-07T11:23:56.995371Z",
     "iopub.status.idle": "2023-11-07T11:24:00.331656Z",
     "shell.execute_reply": "2023-11-07T11:24:00.331174Z",
     "shell.execute_reply.started": "2023-11-07T11:23:56.995611Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "turns\n",
    "while turns>0:\n",
    "    selection_idxes, sub_facts, h = base_selector.select(brute_fact, budget, acc)\n",
    "    if api_use:\n",
    "         ans = [1 if gpt_check(ix_r, c_set)==\"yes\" else 0 for ix_r in selection_idxes]\n",
    "    else:\n",
    "        ans = [1 if ans_list[ix_r]==\"yes\" else 0 for ix_r in selection_idxes]\n",
    "    p_a,p_a_v = brute_fact.compute_ans_p(ans, selection_idxes, acc)\n",
    "    p_post = brute_fact.get_prior_p()*p_a_v / p_a\n",
    "    brute_fact.set_prior_p(p_post)\n",
    "    brute_h_list.append(brute_fact.compute_entropy())\n",
    "    turns -= 1\n",
    "end = time.time()\n",
    "\n",
    "brute_timecost = end - start\n",
    "print(\"brute:{} s\".format(brute_timecost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "approx_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T11:24:00.336739Z",
     "iopub.status.busy": "2023-11-07T11:24:00.336524Z",
     "iopub.status.idle": "2023-11-07T11:24:00.341052Z",
     "shell.execute_reply": "2023-11-07T11:24:00.340629Z",
     "shell.execute_reply.started": "2023-11-07T11:24:00.336725Z"
    }
   },
   "outputs": [],
   "source": [
    "approx_h_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_h_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T11:24:00.341755Z",
     "iopub.status.busy": "2023-11-07T11:24:00.341548Z",
     "iopub.status.idle": "2023-11-07T11:24:00.345135Z",
     "shell.execute_reply": "2023-11-07T11:24:00.344771Z",
     "shell.execute_reply.started": "2023-11-07T11:24:00.341741Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = np.array(all_h_list)\n",
    "random_h_l = n.mean(axis=0, keepdims=True)\n",
    "random_h_l = random_h_l.tolist()[0]\n",
    "random_h_l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
